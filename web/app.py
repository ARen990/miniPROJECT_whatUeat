import streamlit as st
import pickle
import numpy as np
import pandas as pd
from ast import literal_eval
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Layer, Dense
from tensorflow.keras import backend as K
from tensorflow.keras.utils import register_keras_serializable

# Define Attention Layer
@register_keras_serializable()
class AttentionLayer(Layer):
    def __init__(self, **kwargs):
        super(AttentionLayer, self).__init__(**kwargs)
        self.attention = Dense(1, activation='tanh')

    def call(self, inputs):
        weights = self.attention(inputs)  # Compute attention scores
        weights = tf.nn.softmax(weights, axis=1)  # Apply softmax
        return tf.reduce_sum(inputs * weights, axis=1)  # Weighted sum

    def get_config(self):
        config = super(AttentionLayer, self).get_config()
        return config  # Ensures serialization works correctly

# Define Euclidean Distance Function
@register_keras_serializable()
def euclidean_distance(vectors):
    x, y = vectors
    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))

# Register the custom layer and function in `custom_objects`
custom_objects = {'AttentionLayer': AttentionLayer, 'euclidean_distance': euclidean_distance}

model = load_model("D:\MiniProjectML\ML\92_84\siamese_food_recommendation_model.h5", compile=False)

with open("D:\MiniProjectML\ML\92_84\\tokenizer.pickle", 'rb') as handle:
    tokenizer = pickle.load(handle)

max_len = model.input_shape[0][1]


# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î dataset ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå CSV
def load_data():
    file_path = "D:\MiniProjectML\dataset\cleaned1_thailand_foods.csv"  # ‡∏õ‡∏£‡∏±‡∏ö path ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏£‡∏¥‡∏á
    df = pd.read_csv(file_path)
    df["ingredients"] = df["ingredients"].apply(literal_eval)  # ‡πÅ‡∏õ‡∏•‡∏á string -> list
    df["ingredient_text"] = df["ingredients"].apply(lambda ing: " ".join(ing))  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    return df

df = load_data()

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î Tokenizer ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Sequence
tokenizer = Tokenizer()
tokenizer.fit_on_texts(df["ingredient_text"])  # Fit tokenizer ‡∏Å‡∏±‡∏ö dataset ‡∏à‡∏£‡∏¥‡∏á
sequences = tokenizer.texts_to_sequences(df["ingredient_text"])
max_len = max(map(len, sequences))  # ‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á sequence
x_data = pad_sequences(sequences, maxlen=max_len)

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß
custom_objects = {'AttentionLayer': AttentionLayer, 'euclidean_distance': euclidean_distance}
siamese_model = load_model("D:\MiniProjectML\ML\92_84\siamese_food_recommendation_model.h5", compile=False)

def recommend_foods(available_ingredients, allergic_ingredients=[], top_n=10):
    """
    Uses the trained Siamese model to find the most similar recipes based on available ingredients.
    
    Parameters:
    - available_ingredients (list): List of available ingredients (e.g., ["rice", "chicken"])
    - allergic_ingredients (list): List of allergic ingredients (e.g., ["peanuts"])
    - top_n (int): Number of recommended menus to return.

    Returns:
    - DataFrame containing the top recommended menus with allergic ingredients removed.
    """

    if not available_ingredients:
        return "Please enter at least one available ingredient!!!"

    # ‚úÖ Convert input ingredients into text and tokenize
    input_text = " ".join(available_ingredients)
    input_seq = tokenizer.texts_to_sequences([input_text])
    input_seq = pad_sequences(input_seq, maxlen=max_len)

    # ‚úÖ Remove allergic ingredients from all recipes
    modified_df = df.copy()
    modified_df["ingredients"] = modified_df["ingredients"].apply(
        lambda ing: [item for item in ing if item not in allergic_ingredients]
    )
    
    # ‚úÖ Create modified text for tokenization
    modified_df["ingredient_text"] = modified_df["ingredients"].apply(lambda ing: " ".join(ing))
    
    # ‚úÖ Tokenize and pad the modified ingredients
    modified_sequences = tokenizer.texts_to_sequences(modified_df["ingredient_text"])
    modified_sequences = pad_sequences(modified_sequences, maxlen=max_len)

    # ‚úÖ Use Siamese model to compute similarity
    similarities = siamese_model.predict([np.tile(input_seq, (len(modified_sequences), 1)), modified_sequences]).flatten()

    # ‚úÖ Compute importance scores based on matching ingredients
    importance_scores = np.array([
        sum(1 for ing in available_ingredients if ing in row) for row in modified_df["ingredients"]
    ])
    weighted_similarities = similarities + (0.5 * importance_scores / max(importance_scores, default=1))

    # ‚úÖ Select Top-N most similar menus
    top_indices = weighted_similarities.argsort()[-top_n:][::-1]
    recommended_menus = modified_df.iloc[top_indices][["en_name", "th_name", "ingredients"]]

    return recommended_menus

# sample_available_ingredients = ["rice", "chicken"]
# sample_allergic_ingredients = ["peanuts"]

# recommendations = recommend_foods(sample_available_ingredients, sample_allergic_ingredients, top_n=3)

# print("Recommended Menus:")
# print(recommendations)


# Streamlit UI
st.markdown(
    """
    <style>
    .stApp {
        background-color: #FFF3E0;  /* ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏™‡∏µ‡∏Ñ‡∏£‡∏µ‡∏° */
        color: #D32F2F
    }
    .stMarkdown, .stTitle, .stHeader {
        color: #3E2723;  /* ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•‡πÄ‡∏Ç‡πâ‡∏° */
    }
    .stButton > button {
        background-color: #E53935 !important; /* ‡∏õ‡∏∏‡πà‡∏°‡∏™‡∏µ‡πÅ‡∏î‡∏á */
        color: white !important;
        border-radius: 8px;
        padding: 10px;
    }
    .stButton > button:hover {
        background-color: #D32F2F !important; /* ‡∏õ‡∏∏‡πà‡∏°‡∏™‡∏µ‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠ hover */
    }
    /* ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏µ label ‡∏Ç‡∏≠‡∏á text_input ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏î‡∏≥ */
    div[data-testid="stTextInput"] label {
        color: #000000 !important;
        font-weight: bold;  /* ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏≤ */
    }
    div[data-testid="stSlider"] label {
        color: #000000 !important;
        font-weight: bold;  /* ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏≤ */
    }

    /* ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏≠‡∏á input ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏î‡∏≥ */
    .stTextInput > div > div > input {
        background-color: #5D4037  !important;  
        color: #ffffff !important;  
        border-radius: 8px !important;  
        padding: 10px !important;
    }

    /* ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏µ placeholder ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏≤‡∏≠‡πà‡∏≠‡∏ô */
    .stTextInput > div > div > input::placeholder {
        color: #bbbbbb !important;
        font-style: italic;
    }

    /* ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏µ‡∏Ç‡∏≠‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å input */
    .stTextInput > div > div > input:focus {
        border: 2px solid #FF5722 !important; /* ‡πÄ‡∏™‡πâ‡∏ô‡∏Ç‡∏≠‡∏ö‡∏™‡∏µ‡∏™‡πâ‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å */
        outline: none !important;
    }
      /* ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á st.warning() */
    div[data-testid="stAlert"] {
        background-color: #D32F2F !important;  /* ‡∏™‡∏µ‡∏™‡πâ‡∏°‡∏≠‡πà‡∏≠‡∏ô */
        border-radius: 8px !important;
    }
    table {
        width: 100%;
        border-collapse: collapse;
        border: 2px solid #333; /* :white_check_mark: ‡∏Å‡∏£‡∏≠‡∏ö‡∏ô‡∏≠‡∏Å‡∏Ç‡∏≠‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á */
        background-color: #FAF3E0; /* :white_check_mark: ‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≠‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á */
    }

    th, td {
        border: 1px solid #FFFFFF; /* :white_check_mark: ‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ö‡πà‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ã‡∏•‡∏•‡πå */
        padding: 10px;
        text-align: left;
    }

    th {
        background-color: #FF7043; /* :white_check_mark: ‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≠‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå */
        color: white;
        font-weight: bold;
    }

    tr:nth-child(even) {
        background-color: #FFF3E0; /* :white_check_mark: ‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏ñ‡∏ß‡∏Ñ‡∏π‡πà */
    }

    tr:hover {
        background-color: #FFD54F; /* :white_check_mark: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏™‡∏µ‡πÄ‡∏°‡∏∑‡πà‡∏≠ hover */
    }
    </style>
    """,
    unsafe_allow_html=True
)


page = st.sidebar.radio("PAGE", ["Recommended Dishes", "All menu","About"])

if page == "Recommended Dishes":

    st.title("üçΩÔ∏è Recommended Dishes")

    available_ingredients = st.text_input("What do you want to eat? (comma-separated):")
    allergic_ingredients = st.text_input("What you don't want to eat (comma-separated):")

    top_n = st.slider("Number of recommendations:", 1, 10, 3)


    if st.button("Recommend Food"):
        available_ingredients = [ing.strip().lower() for ing in available_ingredients.split(",") if ing.strip()]
        allergic_ingredients = [ing.strip().lower() for ing in allergic_ingredients.split(",") if ing.strip()]

        recommendations = recommend_foods(available_ingredients, allergic_ingredients, top_n)

        if isinstance(recommendations, str):
            st.warning(recommendations)
        else:
            st.write("Recommended Menus")
            # st.dataframe(recommendations, use_container_width=True, hide_index=True)
            st.markdown(
                recommendations.to_html(index=False, escape=False),
                unsafe_allow_html=True
            )

elif page == "All menu":
    st.title("üìú All menu")
    # st.write("‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏ß‡∏°‡πÄ‡∏°‡∏ô‡∏π‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

    # ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏õ‡πá‡∏ô HTML Table ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏™‡πâ‡∏ô‡∏Å‡∏£‡∏≠‡∏ö
    st.markdown(
        """
        <style>
        table {
            width: 100%;
            border-collapse: collapse;
            border: 2px solid #333; /* ‡∏Å‡∏£‡∏≠‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á */
            background-color: #FAF3E0; /* ‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á */
        }
        th, td {
            border: 1px solid #FFFFFF;
            padding: 10px;
            text-align: left;
        }
        th {
            background-color: #FF7043;
            color: white;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #FFF3E0;
        }
        tr:hover {
            background-color: #FFD54F;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏°‡∏ô‡∏π
    st.markdown(df.to_html(index=False, escape=False), unsafe_allow_html=True)

elif page == "About":
    st.title("üìå ABOUT THIS PROJECT")
    
    st.markdown(
        """
        ## Welcome to the Food Recommendation Web App! üçΩÔ∏è
        This application helps you discover food recipes based on your available ingredients.  
        By leveraging **Machine Learning (Siamese Neural Network)**, it calculates recipe similarity  
        and recommends the best matching dishes.

        ---

        ## üõ†Ô∏è Technologies Used
        - **Python, TensorFlow, Streamlit, Pandas**
        - **Siamese Neural Network** for intelligent recommendations
        - **Dataset**: Thai food recipes from `cleaned1_thailand_foods.csv`

        ---

        ## üìç How It Works
        1. **Enter your available ingredients** ‚Üí The app suggests matching recipes  
        2. **Specify unwanted or allergic ingredients** ‚Üí The system filters out those recipes  
        3. **Choose the number of recommendations** ‚Üí Get personalized food suggestions  

        ---

        ## Contact & Resources
        - **GitHub**: [Project Repository](https://github.com/ARen990/miniPROJECT_whatUeat)
        - **Email**: krittimonp28@gmail.com
        - **Youtube**: [Your Profile](https://linkedin.com/in/your-profile)
        """
    )

    # # ‚úÖ Optionally, add an image (like a logo or a sample recommendation)
    # st.image("https://example.com/your-image.jpg", use_column_width=True)
